{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pcheck.semantics import stlBooleanSemantics, stlRobustSemantics\n",
    "from pcheck.series.TimeSeries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting antlr4-python3-runtime==4.7.2\n",
      "  Using cached antlr4_python3_runtime-4.7.2-py3-none-any.whl\n",
      "Installing collected packages: antlr4-python3-runtime\n",
      "Successfully installed antlr4-python3-runtime-4.7.2\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!{sys.executable}  -m pip install antlr4-python3-runtime==4.7.2\n",
    "#!{sys.executable} -m pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict={'S':0,'I':1,'R':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/06_01_2022/SIR_21_40_13/Dataframes/SIR_NUMPY.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2908/1087759595.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/06_01_2022/SIR_21_40_13/Dataframes/SIR_NUMPY.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/enviroments/smc_bnn/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \"\"\"\n\u001b[1;32m    195\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/enviroments/smc_bnn/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/06_01_2022/SIR_21_40_13/Dataframes/SIR_NUMPY.pkl'"
     ]
    }
   ],
   "source": [
    "df_np = pd.read_pickle(\"../Data/06_01_2022/SIR_21_40_13/Dataframes/SIR_NUMPY.pkl\")\n",
    "df_np.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2908/2790605482.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_np\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_np' is not defined"
     ]
    }
   ],
   "source": [
    "X = df_np ['X']\n",
    "Y = df_np['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structure:\n",
    "\n",
    "From **X** we get the series, so the track of values of the variables (S,I,R) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full X: \", df_np['X'].shape)\n",
    "print(\"******************************************************************\")\n",
    "print(\"Single set of experiments of X: \\n(number of runs given an initial state, number of samples, variables we keep track of)\\n\",df_np['X'][0].shape)\n",
    "print(\"******************************************************************\")\n",
    "print(\"Single experiment keeping params fixed:( length of sample,[S,I,R])  \", df_np['X'][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From **Y** we get the set of initial values (S,I,R) for the set of experiments, and the values of the parameters of the model (beta, gamma) from the grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Full Y: \", df_np['Y'].shape)\n",
    "print(\"******************************************************************\")\n",
    "print(\"Params for the set of experiments: \\n(number of experiments of the set, variables we keep track of)\\n\",df_np['Y'][0].shape)\n",
    "print(\"******************************************************************\")\n",
    "print(\"Params [0:2], SIR values[3:] \", df_np['Y'][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractVarAtPosFromX(fullarray, dictionary, variable):\n",
    "    return fullarray[:,dictionary[variable]]\n",
    "\n",
    "def extractInitialValuesFromY(fullarray):\n",
    "    return fullarray[2:]\n",
    "\n",
    "def extractParamsFromY(fullarray):\n",
    "    return fullarray[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = df_np['X'][0][0]\n",
    "metadata = df_np['Y'][3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractVarAtPosFromX(experiment,position_dict, 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractInitialValuesFromY(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractParamsFromY(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSingleVariables(experiment, position_dict):\n",
    "    \n",
    "    VARS = ['S','I','R']\n",
    "    \n",
    "    S = extractVarAtPosFromX(experiment,position_dict, VARS[0])\n",
    "    I = extractVarAtPosFromX(experiment,position_dict,VARS[1])\n",
    "    R = extractVarAtPosFromX(experiment,position_dict, VARS[2])\n",
    "    \n",
    "    return [S,I,R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_traces(X, D):\n",
    "    \n",
    "    n_var_to_track = len(D.items())\n",
    "    S = []\n",
    "    I = []\n",
    "    R = []\n",
    "    \n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        for j in range(X.shape[1]):\n",
    "            \n",
    "            experiment = extractSingleVariables(X[i][j], D)\n",
    "            \n",
    "            S.append(experiment[0])\n",
    "            I.append(experiment[1])\n",
    "            R.append(experiment[2])\n",
    "               \n",
    "    return  pd.DataFrame(list(zip(S, I,R)),columns =['S', 'I', 'R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= get_single_traces(X, position_dict)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var(df, var):\n",
    "    v = ['S', 'I','R']\n",
    "    colors = [\"#d03161\", \"#178a94\",\"#00602d\"]\n",
    "    res = dict(zip(v, colors))\n",
    "    \n",
    "    plt.figure(figsize=(18, 10))\n",
    "    sns.set(style='whitegrid', context='paper')\n",
    "    sns.lineplot(data=np.vstack(df[var]).T,  linewidth=2 ,  palette=(res[var],), alpha=.5,style=None, legend=False,dashes=False);\n",
    "    \n",
    "    \n",
    "def plot_all(df):\n",
    "    \n",
    "    v = ['S', 'I','R']\n",
    "    colors = [\"#d03161\", \"#178a94\",\"#00602d\"]\n",
    "    res = dict(zip(v, colors))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(18, 10))\n",
    "    sns.set(style='whitegrid', context='paper')\n",
    "   # fig.suptitle('Pokemon Stats by Generation')\n",
    "    for i,k in enumerate(res):\n",
    "        sns.lineplot(ax=axes[i],data=np.vstack(df[k]).T,  linewidth=2 ,  palette=(res[k],), alpha=.5,style=None, legend=False,dashes=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var(df, 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(experiment, position_dict,formula):\n",
    "    \n",
    "    VARS = ['S','I','R']\n",
    "    \n",
    "    S = extractVarAtPosFromX(experiment,position_dict, 'S')\n",
    "    I = extractVarAtPosFromX(experiment,position_dict, 'I')\n",
    "    R = extractVarAtPosFromX(experiment,position_dict, 'R')\n",
    "    \n",
    "    T = np.stack([S,I,R])\n",
    "    X = np.arange(0,100, T.shape[1])\n",
    "    \n",
    "\n",
    "    print(S,'\\n',I,'\\n',R)\n",
    "    print(T)\n",
    "    print(T.shape)\n",
    "    TS = TimeSeries(VARS, X, T)\n",
    "    \n",
    "    \n",
    "    return stlBooleanSemantics(TS, 0, formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a single condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '(R > 0) U_[0,19] (I >= 20)'\n",
    "analyze(experiment, position_dict, formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[[1,2],[3,4],[5,6]]\n",
    "\n",
    "np.stack(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(X, Y, D, formula):\n",
    "    INITVAL = []\n",
    "    PARAMS = []\n",
    "    RESULT =[]\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        \n",
    "        for j in range(X.shape[1]):\n",
    "            \n",
    "            experiment = X[i][j]\n",
    "            meta=  Y[i][j]\n",
    "            \n",
    "            \n",
    "            result = analyze(experiment, D, formula)\n",
    "            initval = extractInitialValuesFromY(meta)\n",
    "            params = extractParamsFromY(meta)\n",
    "            \n",
    "            INITVAL.append(initval)\n",
    "            RESULT.append(result)\n",
    "            PARAMS.append(params)\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(list(zip(PARAMS, RESULT,INITVAL)),columns =['Parameters', 'Result', 'InitialValue'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '(R > 0) U_[0,19] (I >= 20)'\n",
    "df_results = test_all(X, Y, position_dict, formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_into_single_cols(df, col, new_cols_names):\n",
    "    df_temp = pd.DataFrame(df[col].to_list(), columns=new_cols_names)\n",
    "    return pd.concat([df,df_temp], axis=1)\n",
    "\n",
    "\n",
    "df_results = split_into_single_cols(df_results,\"InitialValue\", ['S','I','R'])\n",
    "df_results = split_into_single_cols(df_results,\"Parameters\", ['beta','gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "        \n",
    "        self.stoch_mod.output_dir =  self.stoch_mod.model_dir + \"/Risultati\"\n",
    "        self.stoch_mod.temp_dir = self.stoch_mod.model_dir + \"/Temporanea\"\n",
    "        self.dataframes_dir = self.stoch_mod.model_dir + \"/Dataframe\"\n",
    "print(datetime.now().strftime(\"%d/%m/%Y-%H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
